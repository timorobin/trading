{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working with Binance API\n",
    "- https://python-binance.readthedocs.io/en/latest/overview.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "import os\n",
    "import numpy as np, pandas as pd, matplotlib.pyplot as plt\n",
    "import dateparser\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.tsa.stattools import coint\n",
    "from binance.client import Client\n",
    "\n",
    "from utils import get_closes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "API_PUBLIC = os.environ.get(\"B_PUBLIC_KEY\")\n",
    "API_SECRET = os.environ.get(\"B_SECRET_KEY\")\n",
    "client = Client(API_PUBLIC, API_SECRET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'get_log_returns' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-5bf91ce228c1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mltc_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_closes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mltc_sym\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minterval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimedelta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0meth_lr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_log_returns\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meth_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mltc_lr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_log_returns\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mltc_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mdiff\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meth_lr\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mltc_lr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'get_log_returns' is not defined"
     ]
    }
   ],
   "source": [
    "ltc_sym = \"LTCBTC\"\n",
    "eth_sym = \"ETHBTC\"\n",
    "interval = Client.KLINE_INTERVAL_1MINUTE\n",
    "timedelta = dt.timedelta(minutes=10)\n",
    "eth_df = get_closes(client, eth_sym, interval, timedelta)\n",
    "ltc_df = get_closes(client, ltc_sym, interval, timedelta)\n",
    "\n",
    "eth_lr = get_log_returns(eth_df[\"c\"].values)\n",
    "ltc_lr = get_log_returns(ltc_df[\"c\"].values)\n",
    "diff = eth_lr - ltc_lr\n",
    "hedge_ratio = (eth_df[\"c\"]/ltc_df[\"c\"]).values[1:]\n",
    "\n",
    "data = np.stack([eth_lr, ltc_lr, diff, hedge_ratio]).T\n",
    "cols = [\"eth\", \"ltc\", \"diff\", \"hedge_ratio\"]\n",
    "ix = eth_df[\"t1\"].values[1:]\n",
    "df = pd.DataFrame(data=data, columns=cols, index=ix)\n",
    "df[\"time_idx\"] = list(range(len(df)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eth_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eth_df.to_csv(\"data/ethbtc_1min.csv\")\n",
    "# ltc_df.to_csv(\"data/ltcbtc_1min.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = 10\n",
    "t2 = 50\n",
    "fig, ax1 = plt.subplots(1, 1, sharex=True, figsize=(12,6))\n",
    "linewidth = 3\n",
    "alpha = 1\n",
    "ax1.plot(df.iloc[t1:t2][\"eth\"],linewidth=linewidth, alpha=alpha, label=\"eth\")\n",
    "ax1.plot(df.iloc[t1:t2][\"ltc\"], linewidth=linewidth, alpha=alpha, label=\"ltc\")\n",
    "ax1.plot(df.iloc[t1:t2][\"diff\"], \"--g\", linewidth=linewidth, alpha=alpha, label=\"eth - ltc\")\n",
    "ax1.legend(loc=\"best\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# using pytorch forecasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import EarlyStopping\n",
    "import torch\n",
    "\n",
    "from pytorch_forecasting import Baseline, NBeats, TimeSeriesDataSet, DeepAR, TemporalFusionTransformer\n",
    "from pytorch_forecasting.data import NaNLabelEncoder\n",
    "from pytorch_forecasting.data.examples import generate_ar_data\n",
    "from pytorch_forecasting.metrics import SMAPE, NormalDistributionLoss, QuantileLoss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# build dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddf = df[[\"eth\", \"ltc\", \"diff\", \"time_idx\"]]\n",
    "ddf = ddf.set_index(\"time_idx\").reset_index()\n",
    "ddf[\"group\"] = 0\n",
    "ddf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coint_t, p_value, crit_value = coint(ddf[\"eth\"].values, ddf[\"ltc\"].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crit_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coint?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start with just eth returns\n",
    "ddf = df[[\"eth\", \"ltc\", \"diff\", \"time_idx\"]]\n",
    "ddf = ddf.set_index(\"time_idx\").reset_index()\n",
    "ddf[\"group\"] = 0\n",
    "\n",
    "context_length = 45\n",
    "prediction_length = 3\n",
    "training_cutoff = ddf[\"time_idx\"].max() - prediction_length\n",
    "\n",
    "train_tsds = TimeSeriesDataSet(\n",
    "    ddf[ddf[\"time_idx\"] <= training_cutoff],\n",
    "    time_idx = \"time_idx\",\n",
    "    target = \"diff\",\n",
    "    categorical_encoders={\"group\": NaNLabelEncoder().fit(ddf.group)},\n",
    "    group_ids = [\"group\"],\n",
    "    time_varying_unknown_reals=[\"eth\", \"ltc\", \"diff\"],\n",
    "    max_encoder_length=context_length,\n",
    "    max_prediction_length=prediction_length,\n",
    "    target_normalizer=None,\n",
    "    add_relative_time_idx=True\n",
    ")\n",
    "val_tsds = TimeSeriesDataSet.from_dataset(train_tsds, ddf, min_prediction_idx=training_cutoff + 1)\n",
    "\n",
    "batch_size = 128\n",
    "train_dataloader = train_tsds.to_dataloader(train=True, batch_size=batch_size, num_workers=0)\n",
    "val_dataloader = val_tsds.to_dataloader(train=False, batch_size=batch_size, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tsds.get_parameters()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start model building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate baseline absolute error\n",
    "actuals = torch.cat([y[0] for x, y in iter(val_dataloader)])\n",
    "baseline_predictions = Baseline().predict(val_dataloader)\n",
    "SMAPE()(baseline_predictions, actuals.view(1,-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl.seed_everything(42)\n",
    "trainer = pl.Trainer(gpus=0, gradient_clip_val=0.1)\n",
    "\n",
    "model_hyper_params = {\n",
    "    \"learning_rate\": 3e-2,\n",
    "    \"hidden_size\": 16,\n",
    "    \"lstm_layers\": 2,\n",
    "    \"attention_head_size\": 4,\n",
    "    \"output_size\": 7,\n",
    "    \"loss\": QuantileLoss(),\n",
    "    \"time_varying_reals_encoder\": [\"eth\", \"diff\", \"ltc\"]\n",
    "}\n",
    "net = TemporalFusionTransformer.from_dataset(\n",
    "    train_tsds, \n",
    "    **model_hyper_params\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# net.summarize(\"full\")\n",
    "# net.hparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find optimal learning rate\n",
    "res = trainer.tuner.lr_find(net, train_dataloader=train_dataloader, val_dataloaders=val_dataloader, min_lr=1e-5)\n",
    "print(f\"suggested learning rate: {res.suggestion()}\")\n",
    "fig = res.plot(show=True, suggest=True)\n",
    "fig.show()\n",
    "net.hparams.learning_rate = res.suggestion()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stop_callback = EarlyStopping(monitor=\"val_loss\", min_delta=1e-4, patience=10, verbose=False, mode=\"min\")\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=50,\n",
    "    gpus=0,\n",
    "    weights_summary=\"top\",\n",
    "    gradient_clip_val=0.1,\n",
    "    callbacks=[early_stop_callback],\n",
    "    limit_train_batches=30,\n",
    ")\n",
    "\n",
    "trainer.fit(\n",
    "    net,\n",
    "    train_dataloader=train_dataloader,\n",
    "    val_dataloaders=val_dataloader,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_path = trainer.checkpoint_callback.best_model_path\n",
    "best_model = TemporalFusionTransformer.load_from_checkpoint(best_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actuals = torch.cat([y[0] for x, y in iter(val_dataloader)])\n",
    "predictions = best_model.predict(val_dataloader)\n",
    "(actuals - predictions).abs().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_predictions, x = best_model.predict(val_dataloader, mode=\"raw\", return_x=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model.plot_prediction(x, raw_predictions, idx=0, add_loss_to_title=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions, x = best_model.predict(train_dataloader, return_x=True)\n",
    "predictions_vs_actuals = best_model.calculate_prediction_actual_by_variable(x, predictions)\n",
    "best_model.plot_prediction_actual_by_variable(predictions_vs_actuals);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interpretation = best_model.interpret_output(raw_predictions, reduction=\"sum\")\n",
    "best_model.plot_interpretation(interpretation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dependency = best_model.predict_dependency(\n",
    "    val_dataloader.dataset, \"eth\", np.linspace(0, 30, 30), show_progress_bar=True, mode=\"dataframe\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting median and 25% and 75% percentile\n",
    "agg_dependency = dependency.groupby(\"eth\").normalized_prediction.agg(\n",
    "    median=\"median\", q25=lambda x: x.quantile(0.25), q75=lambda x: x.quantile(0.75)\n",
    ")\n",
    "ax = agg_dependency.plot(y=\"median\")\n",
    "ax.fill_between(agg_dependency.index, agg_dependency.q25, agg_dependency.q75, alpha=0.3);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
